# ğŸ•’ Speaking Clock with Azure AI

*A voice-interactive project using Azure Cognitive Services for Speech Recognition and Synthesis*

---

## ğŸ§© Overview

This script â€” **speaking-clock.py** â€” demonstrates how to use **Azure Cognitive Services Speech SDK** to create an interactive **voice-based clock assistant**.
The program listens to your spoken input through the microphone, understands your command, and responds by **speaking the current time aloud** using natural-sounding neural voices.

---

## ğŸ¯ Objectives

* Connect to Azure Speech Services using API key and region credentials.
* Capture **spoken input** from the user via a microphone.
* Recognize and transcribe the spoken phrase using **speech-to-text**.
* Respond with **text-to-speech** synthesis using a neural voice.
* Provide a simple example of integrating speech recognition and synthesis.

---

## ğŸ—‚ï¸ Script Structure

| Section                               | Description                                                              |
| ------------------------------------- | ------------------------------------------------------------------------ |
| **1ï¸âƒ£ Configuration Setup**           | Loads Azure Speech credentials (`KEY`, `REGION`) from a `.env` file.     |
| **2ï¸âƒ£ Speech Service Initialization** | Configures `SpeechConfig` to connect to Azure Cognitive Services.        |
| **3ï¸âƒ£ Speech Recognition**            | Uses `SpeechRecognizer` to capture and transcribe spoken input.          |
| **4ï¸âƒ£ Command Processing**            | Listens for the phrase **"what time is it?"** and triggers the response. |
| **5ï¸âƒ£ Speech Synthesis**              | Uses `SpeechSynthesizer` to speak the current time using a neural voice. |
| **6ï¸âƒ£ Error Handling**                | Gracefully manages failed recognitions or API errors.                    |

---

## âš™ï¸ Requirements

Ensure the following packages are installed:

```bash
python >= 3.8
azure-cognitiveservices-speech = 1.42.0
python-dotenv
```

To install dependencies:

```bash
pip install -r requirements.txt azure-cognitiveservices-speech==1.42.0
```

You will also need an **Azure Speech Service resource** with the following environment variables stored in a `.env` file:

```bash
KEY = "<your_speech_key>"
REGION = "<your_speech_region>"
```

---

## ğŸš€ Getting Started

1. **Clone this repository**

   ```bash
   git clone https://github.com/Hari-Krishnan-Krius/AI102-Project.git
   cd "AI102-Project/Task3 - Recognize and synthesize speech/Code"
   ```

2. **Add your `.env` file** containing your Azure Speech credentials.

3. **Set up your microphone and speakers**
   Ensure your deviceâ€™s microphone and speaker permissions are enabled.

4. **Run the script**

   ```bash
   python speaking-clock.py
   ```

5. **Speak your command**
   When prompted with *â€œSpeak now...â€*, say:

   > â€œWhat time is it?â€

6. **Listen to the response**
   The program will respond with the current time spoken in a natural voice (e.g., *â€œThe time is 10:45.â€*).

---

## ğŸ§  Learning Outcomes

After completing this project, you will be able to:

* Use Azure Cognitive Services for both speech recognition and synthesis.
* Capture and interpret live voice input with Python.
* Convert text responses into spoken output using neural TTS models.
* Build foundational components for **voice-interactive AI applications**.

---

## ğŸ’¡ Highlights

* ğŸ¤ Real-time speech recognition and text-to-speech synthesis.
* âš™ï¸ Fully automated voice-based interaction loop.
* ğŸ§© Simple integration with Azure Speech SDK.
* ğŸ—£ï¸ Uses realistic **neural voice** (e.g., `en-GB-RyanNeural`).
* â° Demonstrates real-time time reporting using Pythonâ€™s `datetime`.

---

## ğŸªª License

This project is released for educational and learning purposes.

---
